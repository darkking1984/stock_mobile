# 08. ë°°í¬ ê°€ì´ë“œ ë° ìš´ì˜ ë¬¸ì„œ

## ğŸš€ ë°°í¬ ì•„í‚¤í…ì²˜

### ì „ì²´ ë°°í¬ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Database      â”‚
â”‚   (Vercel)      â”‚â—„â”€â”€â–ºâ”‚   (Render)      â”‚â—„â”€â”€â–ºâ”‚   (PostgreSQL)  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚   - React App   â”‚    â”‚   - FastAPI     â”‚    â”‚   - User Data   â”‚
â”‚   - Static      â”‚    â”‚   - yfinance    â”‚    â”‚   - Cache       â”‚
â”‚   - CDN         â”‚    â”‚   - Redis       â”‚    â”‚   - Logs        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í™˜ê²½ë³„ ë°°í¬ ì „ëµ
- **Development**: ë¡œì»¬ í™˜ê²½ (Docker Compose)
- **Staging**: Render (Preview Deployments)
- **Production**: Vercel + Render + PostgreSQL

## ğŸ“¦ í”„ë¡ íŠ¸ì—”ë“œ ë°°í¬ (Vercel)

### 1. Vercel ì„¤ì •

#### 1.1 í”„ë¡œì íŠ¸ ì„¤ì •
```json
// frontend/vercel.json
{
  "version": 2,
  "builds": [
    {
      "src": "package.json",
      "use": "@vercel/static-build",
      "config": {
        "distDir": "build"
      }
    }
  ],
  "routes": [
    {
      "src": "/static/(.*)",
      "dest": "/static/$1"
    },
    {
      "src": "/(.*)",
      "dest": "/index.html"
    }
  ],
  "env": {
    "REACT_APP_API_URL": "@api-url"
  }
}
```

#### 1.2 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# Vercel CLIë¡œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
vercel env add REACT_APP_API_URL production
vercel env add REACT_APP_API_URL preview
vercel env add REACT_APP_API_URL development
```

#### 1.3 ë¹Œë“œ ìµœì í™”
```javascript
// frontend/package.json
{
  "scripts": {
    "build": "GENERATE_SOURCEMAP=false react-scripts build",
    "build:analyze": "npm run build && npx webpack-bundle-analyzer build/static/js/*.js"
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  }
}
```

### 2. ë°°í¬ í”„ë¡œì„¸ìŠ¤

#### 2.1 ìë™ ë°°í¬ ì„¤ì •
```yaml
# .github/workflows/deploy-frontend.yml
name: Deploy Frontend

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      run: |
        cd frontend
        npm ci
    
    - name: Run tests
      run: |
        cd frontend
        npm test -- --coverage --watchAll=false
    
    - name: Build
      run: |
        cd frontend
        npm run build
      env:
        REACT_APP_API_URL: ${{ secrets.REACT_APP_API_URL }}
    
    - name: Deploy to Vercel
      uses: amondnet/vercel-action@v25
      with:
        vercel-token: ${{ secrets.VERCEL_TOKEN }}
        vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
        vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
        working-directory: ./frontend
```

#### 2.2 ìˆ˜ë™ ë°°í¬
```bash
# Vercel CLI ì„¤ì¹˜
npm install -g vercel

# ë¡œê·¸ì¸
vercel login

# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
cd frontend
vercel

# í”„ë¡œë•ì…˜ ë°°í¬
vercel --prod
```

## ğŸ”§ ë°±ì—”ë“œ ë°°í¬ (Render)

### 1. Render ì„¤ì •

#### 1.1 ì„œë¹„ìŠ¤ ì„¤ì •
```yaml
# backend/render.yaml
services:
  - type: web
    name: stock-dashboard-api
    env: python
    plan: starter
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn app.main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: DATABASE_URL
        sync: false
      - key: REDIS_URL
        sync: false
      - key: SECRET_KEY
        generateValue: true
      - key: ENVIRONMENT
        value: production
    healthCheckPath: /health
    autoDeploy: true
```

#### 1.2 Docker ë°°í¬ (ì„ íƒì‚¬í•­)
```dockerfile
# backend/Dockerfile
FROM python:3.9-slim

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 1.3 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# Render ëŒ€ì‹œë³´ë“œì—ì„œ ì„¤ì •
DATABASE_URL=postgresql://user:password@host:port/database
REDIS_URL=redis://user:password@host:port
SECRET_KEY=your-secret-key-here
ENVIRONMENT=production
CORS_ORIGINS=https://your-domain.vercel.app
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

#### 2.1 PostgreSQL ì„¤ì •
```sql
-- ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
CREATE DATABASE stock_dashboard;

-- ì‚¬ìš©ì ìƒì„±
CREATE USER stock_user WITH PASSWORD 'secure_password';

-- ê¶Œí•œ ë¶€ì—¬
GRANT ALL PRIVILEGES ON DATABASE stock_dashboard TO stock_user;

-- í™•ì¥ í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
```

#### 2.2 ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
```bash
# Alembic ë§ˆì´ê·¸ë ˆì´ì…˜
cd backend
alembic upgrade head

# ì´ˆê¸° ë°ì´í„° ì‚½ì…
python scripts/seed_data.py
```

### 3. Redis ì„¤ì •

#### 3.1 Redis í´ëŸ¬ìŠ¤í„° ì„¤ì •
```yaml
# redis.conf
maxmemory 256mb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
```

#### 3.2 Redis ì—°ê²° ì„¤ì •
```python
# backend/app/core/redis.py
import redis
from app.core.config import settings

redis_client = redis.from_url(
    settings.REDIS_URL,
    decode_responses=True,
    socket_connect_timeout=5,
    socket_timeout=5,
    retry_on_timeout=True,
    health_check_interval=30
)

# ì—°ê²° í…ŒìŠ¤íŠ¸
def test_redis_connection():
    try:
        redis_client.ping()
        return True
    except Exception as e:
        print(f"Redis connection failed: {e}")
        return False
```

## ğŸ”’ ë³´ì•ˆ ì„¤ì •

### 1. SSL/TLS ì„¤ì •

#### 1.1 Vercel SSL ì„¤ì •
```json
// frontend/vercel.json
{
  "headers": [
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "Strict-Transport-Security",
          "value": "max-age=31536000; includeSubDomains"
        },
        {
          "key": "X-Content-Type-Options",
          "value": "nosniff"
        },
        {
          "key": "X-Frame-Options",
          "value": "DENY"
        },
        {
          "key": "X-XSS-Protection",
          "value": "1; mode=block"
        }
      ]
    }
  ]
}
```

#### 1.2 FastAPI ë³´ì•ˆ ì„¤ì •
```python
# backend/app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.httpsredirect import HTTPSRedirectMiddleware

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í˜¸ìŠ¤íŠ¸ ì„¤ì •
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["your-domain.com", "*.vercel.app"]
)

# HTTPS ë¦¬ë‹¤ì´ë ‰íŠ¸ (í”„ë¡œë•ì…˜ì—ì„œë§Œ)
if settings.ENVIRONMENT == "production":
    app.add_middleware(HTTPSRedirectMiddleware)
```

### 2. í™˜ê²½ ë³€ìˆ˜ ë³´ì•ˆ

#### 2.1 ë¯¼ê°í•œ ì •ë³´ ê´€ë¦¬
```bash
# .env.production (ì ˆëŒ€ ì»¤ë°‹í•˜ì§€ ì•ŠìŒ)
DATABASE_URL=postgresql://user:password@host:port/database
REDIS_URL=redis://user:password@host:port
SECRET_KEY=your-super-secret-key-here
API_KEYS={"yfinance": "your-api-key"}
```

#### 2.2 ì‹œí¬ë¦¿ ê´€ë¦¬
```python
# backend/app/core/config.py
from pydantic_settings import BaseSettings
from typing import Dict, Any
import json

class Settings(BaseSettings):
    DATABASE_URL: str
    REDIS_URL: str
    SECRET_KEY: str
    API_KEYS: str = "{}"
    
    @property
    def api_keys(self) -> Dict[str, str]:
        return json.loads(self.API_KEYS)
    
    class Config:
        env_file = ".env"

settings = Settings()
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 1. ë¡œê¹… ì„¤ì •

#### 1.1 FastAPI ë¡œê¹…
```python
# backend/app/core/logging.py
import logging
import sys
from loguru import logger
from app.core.config import settings

# ë¡œê·¸ ì„¤ì •
logger.remove()
logger.add(
    sys.stdout,
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    level="INFO" if settings.ENVIRONMENT == "production" else "DEBUG"
)

# íŒŒì¼ ë¡œê¹… (í”„ë¡œë•ì…˜)
if settings.ENVIRONMENT == "production":
    logger.add(
        "logs/app.log",
        rotation="1 day",
        retention="30 days",
        compression="zip",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
    )

# FastAPI ë¡œê±° ì„¤ì •
class InterceptHandler(logging.Handler):
    def emit(self, record):
        try:
            level = logger.level(record.levelname).name
        except ValueError:
            level = record.levelno

        frame, depth = logging.currentframe(), 2
        while frame.f_code.co_filename == logging.__file__:
            frame = frame.f_back
            depth += 1

        logger.opt(depth=depth, exception=record.exc_info).log(
            level, record.getMessage()
        )

logging.basicConfig(handlers=[InterceptHandler()], level=0, force=True)
```

#### 1.2 API ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
```python
# backend/app/middleware/logging.py
import time
import json
from fastapi import Request, Response
from loguru import logger

async def logging_middleware(request: Request, call_next):
    start_time = time.time()
    
    # ìš”ì²­ ë¡œê¹…
    logger.info(f"Request: {request.method} {request.url}")
    
    # ìš”ì²­ ë³¸ë¬¸ ë¡œê¹… (POST/PUTë§Œ)
    if request.method in ["POST", "PUT"]:
        try:
            body = await request.body()
            if body:
                logger.debug(f"Request body: {body.decode()}")
        except Exception as e:
            logger.warning(f"Failed to log request body: {e}")
    
    # ì‘ë‹µ ì²˜ë¦¬
    response = await call_next(request)
    
    # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
    process_time = time.time() - start_time
    
    # ì‘ë‹µ ë¡œê¹…
    logger.info(
        f"Response: {response.status_code} - {process_time:.3f}s"
    )
    
    # ì‘ë‹µ í—¤ë”ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
    response.headers["X-Process-Time"] = str(process_time)
    
    return response
```

### 2. í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸

#### 2.1 í—¬ìŠ¤ì²´í¬ êµ¬í˜„
```python
# backend/app/api/health.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.core.redis import redis_client
import yfinance as yf

router = APIRouter()

@router.get("/health")
async def health_check():
    """ê¸°ë³¸ í—¬ìŠ¤ì²´í¬"""
    return {"status": "healthy", "timestamp": datetime.utcnow()}

@router.get("/health/detailed")
async def detailed_health_check(db: Session = Depends(get_db)):
    """ìƒì„¸ í—¬ìŠ¤ì²´í¬"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow(),
        "checks": {}
    }
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬
    try:
        db.execute("SELECT 1")
        health_status["checks"]["database"] = "healthy"
    except Exception as e:
        health_status["checks"]["database"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    # Redis ì²´í¬
    try:
        redis_client.ping()
        health_status["checks"]["redis"] = "healthy"
    except Exception as e:
        health_status["checks"]["redis"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    # yfinance API ì²´í¬
    try:
        ticker = yf.Ticker("AAPL")
        info = ticker.info
        if info:
            health_status["checks"]["yfinance"] = "healthy"
        else:
            health_status["checks"]["yfinance"] = "unhealthy: no data"
            health_status["status"] = "unhealthy"
    except Exception as e:
        health_status["checks"]["yfinance"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    return health_status
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### 3.1 ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```python
# backend/app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# ë©”íŠ¸ë¦­ ì •ì˜
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

ACTIVE_CONNECTIONS = Gauge(
    'active_connections',
    'Number of active connections'
)

# ë¯¸ë“¤ì›¨ì–´ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
async def metrics_middleware(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    # ìš”ì²­ ìˆ˜ ì¦ê°€
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path,
        status=response.status_code
    ).inc()
    
    # ìš”ì²­ ì‹œê°„ ê¸°ë¡
    REQUEST_DURATION.labels(
        method=request.method,
        endpoint=request.url.path
    ).observe(time.time() - start_time)
    
    return response
```

## ğŸ”„ ë°±ì—… ë° ë³µêµ¬

### 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…

#### 1.1 ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# scripts/backup.sh

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
DB_URL="postgresql://user:password@host:port/database"
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="stock_dashboard_$DATE.sql"

# ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p $BACKUP_DIR

# PostgreSQL ë°±ì—…
pg_dump $DB_URL > $BACKUP_DIR/$BACKUP_FILE

# ì••ì¶•
gzip $BACKUP_DIR/$BACKUP_FILE

# 30ì¼ ì´ìƒ ëœ ë°±ì—… ì‚­ì œ
find $BACKUP_DIR -name "*.sql.gz" -mtime +30 -delete

echo "Backup completed: $BACKUP_FILE.gz"
```

#### 1.2 ë°±ì—… ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# scripts/restore.sh

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
DB_URL="postgresql://user:password@host:port/database"
BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# ë°±ì—… íŒŒì¼ í™•ì¸
if [ ! -f "$BACKUP_FILE" ]; then
    echo "Backup file not found: $BACKUP_FILE"
    exit 1
fi

# ë³µêµ¬ ì‹¤í–‰
gunzip -c $BACKUP_FILE | psql $DB_URL

echo "Restore completed from: $BACKUP_FILE"
```

### 2. Redis ë°±ì—…

#### 2.1 Redis ë°±ì—… ì„¤ì •
```bash
# Redis ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# scripts/redis_backup.sh

REDIS_HOST="localhost"
REDIS_PORT="6379"
BACKUP_DIR="/backups/redis"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# Redis ë°±ì—…
redis-cli -h $REDIS_HOST -p $REDIS_PORT BGSAVE

# ë°±ì—… íŒŒì¼ ë³µì‚¬
cp /var/lib/redis/dump.rdb $BACKUP_DIR/dump_$DATE.rdb

# ì••ì¶•
gzip $BACKUP_DIR/dump_$DATE.rdb

# 7ì¼ ì´ìƒ ëœ ë°±ì—… ì‚­ì œ
find $BACKUP_DIR -name "dump_*.rdb.gz" -mtime +7 -delete

echo "Redis backup completed: dump_$DATE.rdb.gz"
```

## ğŸš¨ ì¥ì•  ëŒ€ì‘

### 1. ì¥ì•  ê°ì§€ ë° ì•Œë¦¼

#### 1.1 ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/monitor.py
import requests
import smtplib
from email.mime.text import MIMEText
import time
from loguru import logger

class HealthMonitor:
    def __init__(self, endpoints, email_config):
        self.endpoints = endpoints
        self.email_config = email_config
    
    def check_endpoint(self, url):
        try:
            response = requests.get(url, timeout=10)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Health check failed for {url}: {e}")
            return False
    
    def send_alert(self, message):
        try:
            msg = MIMEText(message)
            msg['Subject'] = 'Stock Dashboard Alert'
            msg['From'] = self.email_config['from']
            msg['To'] = self.email_config['to']
            
            with smtplib.SMTP(self.email_config['smtp_server']) as server:
                server.starttls()
                server.login(self.email_config['username'], self.email_config['password'])
                server.send_message(msg)
            
            logger.info("Alert email sent")
        except Exception as e:
            logger.error(f"Failed to send alert: {e}")
    
    def run(self):
        while True:
            for name, url in self.endpoints.items():
                if not self.check_endpoint(url):
                    message = f"Health check failed for {name}: {url}"
                    self.send_alert(message)
            
            time.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì²´í¬

if __name__ == "__main__":
    endpoints = {
        "API": "https://your-api.render.com/health",
        "Frontend": "https://your-app.vercel.app"
    }
    
    email_config = {
        "smtp_server": "smtp.gmail.com",
        "username": "your-email@gmail.com",
        "password": "your-app-password",
        "from": "your-email@gmail.com",
        "to": "admin@your-domain.com"
    }
    
    monitor = HealthMonitor(endpoints, email_config)
    monitor.run()
```

### 2. ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

#### 2.1 ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# scripts/restart_service.sh

SERVICE_NAME="stock-dashboard-api"
MAX_RESTARTS=3
RESTART_COUNT=0

while [ $RESTART_COUNT -lt $MAX_RESTARTS ]; do
    # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    if curl -f http://localhost:8000/health > /dev/null 2>&1; then
        echo "Service is healthy"
        exit 0
    else
        echo "Service is unhealthy, restarting..."
        RESTART_COUNT=$((RESTART_COUNT + 1))
        
        # ì„œë¹„ìŠ¤ ì¬ì‹œì‘
        systemctl restart $SERVICE_NAME
        
        # ì¬ì‹œì‘ ëŒ€ê¸°
        sleep 30
        
        # í—¬ìŠ¤ì²´í¬ ì¬ì‹œë„
        for i in {1..10}; do
            if curl -f http://localhost:8000/health > /dev/null 2>&1; then
                echo "Service recovered after restart"
                exit 0
            fi
            sleep 10
        done
    fi
done

echo "Service failed to recover after $MAX_RESTARTS restarts"
exit 1
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹± ì „ëµ

#### 1.1 Redis ìºì‹± êµ¬í˜„
```python
# backend/app/services/cache_service.py
import redis
import json
import pickle
from typing import Any, Optional
from app.core.config import settings

class CacheService:
    def __init__(self):
        self.redis = redis.from_url(settings.REDIS_URL)
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        try:
            data = self.redis.get(key)
            if data:
                return pickle.loads(data)
            return None
        except Exception as e:
            logger.error(f"Cache get error: {e}")
            return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        try:
            data = pickle.dumps(value)
            self.redis.setex(key, ttl, data)
        except Exception as e:
            logger.error(f"Cache set error: {e}")
    
    def delete(self, key: str):
        """ìºì‹œì—ì„œ ë°ì´í„° ì‚­ì œ"""
        try:
            self.redis.delete(key)
        except Exception as e:
            logger.error(f"Cache delete error: {e}")
    
    def clear_pattern(self, pattern: str):
        """íŒ¨í„´ì— ë§ëŠ” ìºì‹œ ì‚­ì œ"""
        try:
            keys = self.redis.keys(pattern)
            if keys:
                self.redis.delete(*keys)
        except Exception as e:
            logger.error(f"Cache clear pattern error: {e}")
```

### 2. CDN ì„¤ì •

#### 2.1 Vercel CDN ìµœì í™”
```json
// frontend/vercel.json
{
  "headers": [
    {
      "source": "/static/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "public, max-age=31536000, immutable"
        }
      ]
    },
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "public, max-age=0, must-revalidate"
        }
      ]
    }
  ]
}
```

ì´ì œ ì‹¤ì œ ê°œë°œì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ë¨¼ì € í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ê³  ê¸°ë³¸ ì„¤ì •ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
<ï½œtoolâ–callsâ–beginï½œ><ï½œtoolâ–callâ–beginï½œ>
run_terminal_cmd